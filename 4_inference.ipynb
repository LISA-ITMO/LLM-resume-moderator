{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from typing import Dict\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "INFERENCE_MODEL = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "DEEPINFRA_TOKEN = os.environ.get('DEEPINFRA_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rools = '\\n'.join(map(str, json.load(open('data/resume_rools.json'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Ты — ИИ-модератор резюме. Проверь текст резюме на соответствие следующим правилам. Если есть нарушения, верни JSON-объект с типом нарушения и фрагментом текста, который нарушает правило. Если нарушений нет, верни статус \"OK\".\n",
    "\n",
    "**Правила:** \n",
    "{rools}\n",
    "\n",
    "**Инструкции:**\n",
    "\n",
    "- Тщательно проанализируй каждое предложение в резюме.\n",
    "- Если нарушений нет, верни \"status\": \"OK\" и пустой массив violated_rules.\n",
    "- Если фрагмент нарушает правило, укажи его точную цитату в resume_fragment.\n",
    "- Ответ должен содержать твои рассуждения по каждому правилу оканчивающийся вердиктом, затем должен быть результат в формате JSON, без Markdown и комментариев.\n",
    "\n",
    "Формат ответа: Рассуждения:, Результат: { \"status\": \"OK\" | \"violation\", \"violated_rules\": [] | [ { \"id\": \"rule_id\", \"condition\": \"Текст условия правила на русском\", \"resume_fragment\": \"Точная цитата из резюме\" } ] }\n",
    "\n",
    "**Текст резюме:**\n",
    "{resume_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ты — ИИ-модератор резюме. Проверь текст резюме на соответствие следующим правилам. Если есть нарушения, верни JSON-объект с типом нарушения и фрагментом текста, который нарушает правило. Если нарушений нет, верни статус \"OK\".\n",
      "\n",
      "**Правила:** \n",
      "{'id': 'rule_1', 'condition': 'Резюме должно содержать информацию о трудовой деятельности если желаемая должность требует опыта'}\n",
      "{'id': 'rule_2', 'condition': 'Резюме должно содержать профессию/должность или должности, на которые претендует соискатель, должность должжна быть реальной профессией'}\n",
      "{'id': 'rule_4', 'condition': 'Резюме должно быть заполнено на русском языке'}\n",
      "{'id': 'rule_5', 'condition': 'Информация о работодателе не должна содержать сведений, не относящихся к работодателю, если работодатель ИП это не нарушение правил'}\n",
      "{'id': 'rule_6', 'condition': 'Информация о резюме не должна содержать сведений, не относящихся к соискателю'}\n",
      "{'id': 'rule_7', 'condition': 'Информация не должна содержать слова и выражения, не соответствующие нормам современного русского литературного языка, допустимы стилистические неточности, но главное чтобы не было матов и токсичности'}\n",
      "\n",
      "**Инструкции:**\n",
      "\n",
      "- Тщательно проанализируй каждое предложение в резюме.\n",
      "- Если нарушений нет, верни \"status\": \"OK\" и пустой массив violated_rules.\n",
      "- Если фрагмент нарушает правило, укажи его точную цитату в resume_fragment.\n",
      "- Ответ должен содержать твои рассуждения по каждому правилу оканчивающийся вердиктом, затем должен быть результат в формате JSON, без Markdown и комментариев.\n",
      "\n",
      "Формат ответа: Рассуждения:, Результат: { \"status\": \"OK\" | \"violation\", \"violated_rules\": [] | [ { \"id\": \"rule_id\", \"condition\": \"Текст условия правила на русском\", \"resume_fragment\": \"Точная цитата из резюме\" } ] }\n",
      "\n",
      "**Текст резюме:**\n",
      "{resume_text}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt.replace('{rools}', rools))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_answer(response_str: str) -> Dict[str, str]:\n",
    "    parts = response_str.split(\"Результат:\")\n",
    "    \n",
    "    reasoning = parts[0].replace(\"Рассуждения:\\n\", \"\").strip()\n",
    "\n",
    "    try:\n",
    "        result_dict = json.loads(parts[1])\n",
    "    except json.JSONDecodeError:\n",
    "        result_dict = {\"error\": \"Invalid JSON format\"}\n",
    "    \n",
    "    return {\n",
    "        \"reasoning\": reasoning,\n",
    "        \"result\": result_dict\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(resume_text: str) -> Dict[str, str]:\n",
    "    url = \"https://api.deepinfra.com/v1/openai/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {DEEPINFRA_TOKEN}\"\n",
    "    }\n",
    "    \n",
    "    formatted_prompt = prompt.replace('{rools}', rools).replace('{resume_text}', resume_text)\n",
    "    \n",
    "    data = {\n",
    "        \"model\": INFERENCE_MODEL,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": formatted_prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    answer_content = response.json()['choices'][0]['message']['content']\n",
    "    \n",
    "    return parse_answer(answer_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/processed_resume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 13:13:27,188 - INFO - Checkpoint saved at index 0\n",
      "2025-02-24 13:23:42,580 - INFO - Checkpoint saved at index 20\n",
      "2025-02-24 13:39:37,605 - INFO - Checkpoint saved at index 40\n",
      "2025-02-24 13:51:23,843 - INFO - Checkpoint saved at index 60\n",
      "2025-02-24 14:08:39,584 - INFO - Checkpoint saved at index 80\n",
      "2025-02-24 14:21:17,773 - INFO - Checkpoint saved at index 100\n",
      "2025-02-24 14:34:46,062 - INFO - Checkpoint saved at index 120\n",
      "2025-02-24 14:45:10,678 - INFO - Checkpoint saved at index 140\n",
      "2025-02-24 14:58:44,553 - INFO - Checkpoint saved at index 160\n",
      "2025-02-24 15:08:07,653 - INFO - Checkpoint saved at index 180\n",
      "2025-02-24 15:18:31,278 - INFO - Checkpoint saved at index 200\n",
      "2025-02-24 15:31:56,468 - INFO - Checkpoint saved at index 220\n",
      " 26%|██▌       | 234/905 [2:28:26<4:16:10, 22.91s/it]  "
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('processing.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def process_dataframe(df, checkpoint_interval=20):\n",
    "    last_checkpoint = get_last_checkpoint()\n",
    "    start_index = 0\n",
    "    results = []\n",
    "    \n",
    "    if last_checkpoint:\n",
    "        start_index = last_checkpoint['index'] + 1\n",
    "        results = last_checkpoint['results']\n",
    "        logging.info(f\"Resuming from index {start_index}\")\n",
    "\n",
    "    try:\n",
    "        for i in tqdm(range(start_index, len(df)), initial=start_index, total=len(df)):\n",
    "            time.sleep(5)\n",
    "            try:\n",
    "                result = get_answer(df.text_data[i])\n",
    "                results.append(result)\n",
    "                \n",
    "                if (i - start_index) % checkpoint_interval == 0:\n",
    "                    save_checkpoint(i, results)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing row {i}: {str(e)}\")\n",
    "                results.append({'error': str(e)})\n",
    "                \n",
    "        save_checkpoint(len(df)-1, results)\n",
    "        return pd.DataFrame(results)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"Process interrupted. Saving last checkpoint...\")\n",
    "        save_checkpoint(i-1, results)\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "def save_checkpoint(index, results):\n",
    "    checkpoint = {\n",
    "        'timestamp': datetime.now(),\n",
    "        'index': index,\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    with open('checkpoint.pkl', 'wb') as f:\n",
    "        pickle.dump(checkpoint, f)\n",
    "        \n",
    "    logging.info(f\"Checkpoint saved at index {index}\")\n",
    "\n",
    "def get_last_checkpoint():\n",
    "    if os.path.exists('checkpoint.pkl'):\n",
    "        try:\n",
    "            with open('checkpoint.pkl', 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading checkpoint: {str(e)}\")\n",
    "\n",
    "\n",
    "result_df = process_dataframe(df)\n",
    "result_df.to_csv('final_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['llama_answer'] = result_df['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['llama_status'] = result_df['result'].apply(lambda el: el.get('status'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['llama_reasoning'] = result_df['reasoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_status\n",
       "OK           602\n",
       "violation    300\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['llama_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198    violation\n",
       "242    violation\n",
       "425           OK\n",
       "428    violation\n",
       "822    violation\n",
       "Name: llama_status, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Результат'] == 'Отклонено', 'llama_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_status\n",
       "OK           497\n",
       "violation    249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Результат'] == 'Принято', 'llama_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative = (df.loc[df['Результат'] == 'Отклонено', 'llama_status'] == 'OK').astype(int).sum()\n",
    "false_positive = (df.loc[df['Результат'] == 'Принято', 'llama_status'] == 'violation').astype(int).sum()\n",
    "recall = (df.loc[df['Результат'] == 'Отклонено', 'llama_status'] == 'violation').astype(int).mean()\n",
    "precision = (df.loc[df['Результат'] == 'Принято', 'llama_status'] == 'OK').astype(int).mean()\n",
    "f1_score = 2 * (recall * precision) / (recall + precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false negative: 1\n",
      "false positive: 249\n",
      "recall: 0.80\n",
      "precision: 0.66\n",
      "f1-score: 0.73\n"
     ]
    }
   ],
   "source": [
    "print(f'false negative: {false_negative}')\n",
    "print(f'false positive: {false_positive}')\n",
    "print(f'recall: {recall:.2f}')\n",
    "print(f'precision: {precision:.2f}')\n",
    "print(f'f1-score: {f1_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/processed_resume.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
